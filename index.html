<html>

<head>
    <link rel="stylesheet" href="style.css">

    <script src="main.js"></script>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Hobby</title>
</head>

<body>
    <button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>
    <ul class="menu">
        <li class="link"><a href="#About">About</a></li>
        <li class="link"><a href="#MFEOC">My Favourite Editors Of Coding</a></li>
        <li class="link"><a href="#TFP">Tips For Programing</a></li>
        <li class="link"><a href="#WIAP">What Is A Programmer?</a></li>
        <li class="link"><a href="#PL">Programming Language</a></li>
        <li class="link"><a href="#V">Videos Of Coding</a></li>
        <li class="link"><a href="#C">View Review of coding</a></li>
        <li class="link"><a href="#I">Inspiration</a></li>
        <li class="link"><a href="#C">Contacts</a></li>
    </ul>
    <div class="work">
        <img src="https://images.unsplash.com/photo-1515879218367-8466d910aaa4?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb&ixid=eyJhcHBfaWQiOjE0NTg5fQ" class="B"></img>
        <h1>MY FAVOURITE HOBBY</h1>
        <h1>Programing</h1>
        <hr>
        </hr>
        <h1 id="About">About</h1>
        <br></br>
        <h2 class="o">[Computer programming]</h2>
        <h3>Computer programming is the process of designing and building an executable computer program to accomplish a specific computing result or to perform a specific task. Programming involves tasks such as: analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding).[1][2] The source code of a program is written in one or more languages that are intelligible to programmers, rather than machine code, which is directly executed by the central processing unit. The purpose of programming is to find a sequence of instructions that will automate the performance of a task (which can be as complex as an operating system) on a computer, often for solving a given problem. Proficient programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic.

            Tasks accompanying and related to programming include: testing, debugging, source code maintenance, implementation of build systems, and management of derived artifacts, such as the machine code of computer programs. These might be considered part of the programming process, but often the term software development is used for this larger process with the term programming, implementation, or coding reserved for the actual writing of code. Software engineering combines engineering techniques with software development practices. Reverse engineering is the opposite process. A hacker is any skilled computer expert that uses their technical knowledge to overcome a problem, but it can also mean a security hacker in common language.</h3>
        <h2>[History]</h2>
        <h3>Programmable devices have existed for centuries. As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices.[3][4] In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams.[5][6] In 1801, the Jacquard loom could produce entirely different weaves by changing the "program" – a series of pasteboard cards with holes punched in them.

            Code-breaking algorithms have also existed for centuries. In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.[7]

            The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.[8]n the 1880s Herman Hollerith invented the concept of storing data in machine-readable form.[9] Later a control panel (plugboard) added to his 1906 Type I Tabulator allowed it to be programmed for different jobs, and by the late 1940s, unit record equipment such as the IBM 602 and IBM 604, were programmed by control panels in a similar way; as were the first electronic computers. However, with the concept of the stored-program computers introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.[citation needed]

            Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation. Assembly languages were soon developed that let the programmer specify instruction in a text format, (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses. However, because an assembly language is little more than a different notation for a machine language, any two machines with different instruction sets also have different assembly languages.
            High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware. FORTRAN, the first widely used high-level language to have a functional implementation, came out in 1957[10] and many other languages were soon developed – in particular, COBOL aimed at commercial data processing, and Lisp for computer research.

            Programs were mostly still entered using punched cards or paper tape. See computer programming in the punch card era. By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers. Text editors (programs themselves) were developed that allowed changes and corrections to be made much more easily than with punched cards.</h3>
        <h2>[Modern programming]</h2>
        <h2>Quality requirements</h2>
        <h3>Whatever the approach to development may be, the final program must satisfy some fundamental properties. The following properties are among the most important:

            Reliability: how often the results of a program are correct. This depends on conceptual correctness of algorithms, and minimization of programming mistakes, such as mistakes in resource management (e.g., buffer overflows and race conditions) and logic errors (such as division by zero or off-by-one errors).
            Robustness: how well a program anticipates problems due to errors (not bugs). This includes situations such as incorrect, inappropriate or corrupt data, unavailability of needed resources such as memory, operating system services and network connections, user error, and unexpected power outages.
            Usability: the ergonomics of a program: the ease with which a person can use the program for its intended purpose or in some cases even unanticipated purposes. Such issues can make or break its success even regardless of other issues. This involves a wide range of textual, graphical and sometimes hardware elements that improve the clarity, intuitiveness, cohesiveness and completeness of a program's user interface.
            Portability: the range of computer hardware and operating system platforms on which the source code of a program can be compiled/interpreted and run. This depends on differences in the programming facilities provided by the different platforms, including hardware and operating system resources, expected behavior of the hardware and operating system, and availability of platform specific compilers (and sometimes libraries) for the language of the source code.
            Maintainability: the ease with which a program can be modified by its present or future developers in order to make improvements or customisations, fix bugs and security holes, or adapt it to new environments. Good practices during initial development make the difference in this regard. This quality may not be directly apparent to the end user but it can significantly affect the fate of a program over the long term.
            Efficiency/performance: Measure of system resources a program consumes (processor time, memory space, slow devices such as disks, network bandwidth and to some extent even user interaction): the less, the better. This also includes careful management of resources, for example cleaning up temporary files and eliminating memory leaks. This is often discussed under the shadow of a chosen programming language. The language certainly effects the performance, but even slower languages such as python can execute programs, from a human perspective, instantly. The speed, resource usage, and performance may be important for some programs which require it, but many programs that are not bottlenecked by speed of hardware, in general, do not require optimization.</h3>
        <h2>Readability of source code</h2>
        <h3>In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code. It affects the aspects of quality above, including portability, usability and most importantly maintainability.

            Readability is important because programmers spend the majority of their time reading, trying to understand and modifying existing source code, rather than writing new source code. Unreadable code often leads to bugs, inefficiencies, and duplicated code. A study[11] found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.

            Following a consistent programming style often helps readability. However, readability is more than just programming style. Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability.[12] Some of these factors include:

            Different indent styles (whitespace)
            Comments
            Decomposition
            Naming conventions for objects (such as variables, classes, procedures, etc.)
            The presentation aspects of this (such as indents, line breaks, color highlighting, and so on) are often handled by the source code editor, but the content aspects reflect the programmer's talent and skills.

            Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display. Integrated development environments (IDEs) aim to integrate all such help. Techniques like Code refactoring can enhance readability.</h3>
        <h2>Algorithmic complexity</h2>
        <h3>The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problem. For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input. Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.</h3>
        <h2>Chess algorithms as an example</h2>
        <h3>"Programming a Computer for Playing Chess" was a 1950 paper that evaluated a "minimax" algorithm that is part of the history of algorithmic complexity; a course on IBM's Deep Blue (chess computer) is part of the computer science curriculum at Stanford University.</h3>
        <h2>Methodologies</h2>
        <h3>The first step in most formal software development processes is requirements analysis, followed by testing to determine value modeling, implementation, and failure elimination (debugging). There exist a lot of differing approaches for each of those tasks. One approach popular for requirements analysis is Use Case analysis. Many programmers use forms of Agile software development where the various stages of formal software development are more integrated together into short cycles that take a few weeks rather than years. There are many approaches to the Software development process.

            Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA). The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.

            A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).

            Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.</h3>
        <h2>Measuring language usage</h2>
        <h3>It is very difficult to determine what are the most popular of modern programming languages. Methods of measuring programming language popularity include: counting the number of job advertisements that mention the language,[14] the number of books sold and courses teaching the language (this overestimates the importance of newer languages), and estimates of the number of existing lines of code written in the language (this underestimates the number of users of business languages such as COBOL).

            Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications. For example, COBOL is still strong in corporate data centers[15] often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software. Many applications use a mix of several languages in their construction and use. New languages are generally designed around the syntax of a prior language with new functionality added, (for example C++ adds object-orientation to C, and Java adds memory management and bytecode to C++, but as a result, loses efficiency and the ability for low-level manipulation).</h3>
        <h2>Debugging</h2>
        <h3>Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users. Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages. Use of a static code analysis tool can help detect some possible problems. Normally the first step in debugging is to attempt to reproduce the problem. This can be a non-trivial task, for example as with parallel processes or some unusual software bugs. Also, specific user environment and usage history can make it difficult to reproduce the problem.

            After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug. For example, a bug in a compiler can make it crash when passing some large source file. However, after simplification of the test case, only few lines from the original source file can be sufficient to reproduce the same crash. Such simplification can be done manually, using a divide-and-conquer approach. The programmer will try to remove some parts of original test case and check if the problem still exists. When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.

            Debugging is often done with IDEs like Eclipse, Visual Studio, Xcode, Kdevelop, NetBeans and Code::Blocks. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line. Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.</h3>
        <h2>[Programming languages]</h2>
        <h3>Different programming languages support different styles of programming (called programming paradigms). The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference. Ideally, the programming language best suited for the task at hand will be selected. Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute. Languages form an approximate spectrum from "low-level" to "high-level"; "low-level" languages are typically more machine-oriented and faster to execute, whereas "high-level" languages are more abstract and easier to use but execute less quickly. It is usually easier to code in "high-level" languages than in "low-level" ones.

            Allen Downey, in his book How To Think Like A Computer Scientist, writes:

            The details look different in different languages, but a few basic instructions appear in just about every language:
            Input: Gather data from the keyboard, a file, or some other device.
            Output: Display data on the screen or send data to a file or other device.
            Arithmetic: Perform basic arithmetical operations like addition and multiplication.
            Conditional Execution: Check for certain conditions and execute the appropriate sequence of statements.
            Repetition: Perform some action repeatedly, usually with some variation.
            Many computer languages provide a mechanism to call functions provided by shared libraries. Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.</h3>
        <h2>Programmers</h2>
        <h3>Computer programmers are those who write computer software. Their jobs usually involve:</h3>
        <ul>
            <li class="Hi">Coding</li>
            <li class="Hi">Debugging</li>
            <li class="Hi">Documentation</li>
            <li class="Hi">Integration</li>
            <li class="Hi">Maintenance</li>
        </ul>
        <hr>
        </hr>
        <h1 class="o">My Favourite Editors Of Coding</h1>
        <h2 id="MFEOC">My Favourite Editors of coding are:</h2>
        <ul>
            <li class="EVE">Codepen.io</li>
            <li class="EVE">Brackets</li>
            <li class="EVE">Code.org</li>
            <li class="EVE">Thunkable</li>
        </ul>
        <hr>
        </hr>
        <h2 id="TFP">Tips For Programing</h2>
        <h3>In aspect and functional programming, advice describes a class of functions which modify other functions when the latter are run; it is a certain function, method or procedure that is to be applied at a given join point of a program.

            The following is taken from a discussion at the mailing list aosd-discuss. Pascal Costanza contributed the following:

            The term advice goes back to the term advising as introduced by Warren Teitelman in his PhD thesis in 1966. Here is a quote from Chapter 3 of his thesis:

            Advising is the basic innovation in the model, and in the PILOT system. Advising consists of inserting new procedures at any or all of the entry or exit points to a particular procedure (or class of procedures). The procedures inserted are called "advice procedures" or simply "advice".
            Since each piece of advice is itself a procedure, it has its own entries and exits. In particular, this means that the execution of advice can cause the procedure that it modifies to be bypassed completely, e.g., by specifying as an exit from the advice one of the exits from the original procedure; or the advice may change essential variables and continue with the computation so that the original procedure is executed, but with modified variables. Finally, the advice may not alter the execution or affect the original procedure at all, e.g., it may merely perform some additional computation such as printing a message or recording history. Since advice can be conditional, the decision as to what is to be done can depend on the results of the computation up to that point.
            The principal advantage of advising is that the user need not be concerned about the details of the actual changes in his program, nor the internal representation of advice. He can treat the procedure to be advised _as a unit_, a single block, and make changes to it without concern for the particulars of this block. This may be contrasted with editing in which the programmer must be cognizant of the internal structure of the procedure.
            "Advising" found its way into BBN Lisp and later into Xerox PARC's Interlisp.

            It also found its way to Flavors, the first object-oriented extension to Lisp developed at MIT. They were subsumed under the notion of method combination. [1][a]

            Since method combination and macros are closely related, it's also interesting to note that the first macro system was described in 1963, three years before Warren Teitelman's PhD thesis.</h3>
        <h2>Use</h2>
        <h3>The practical use of advice functions is generally to modify or otherwise extend the behavior of functions which cannot be easily modified or extended. The Emacspeak Emacs-addon makes extensive use of advice: it must modify thousands of existing Emacs modules and functions such that it can produce audio output for the blind corresponding to the visual presentation, but it would be infeasible to copy all of them and redefine them to produce audio output in addition to their normal outputs; so, the Emacspeak programmers define advice functions which run before and after.

            Another Emacs example; suppose after one corrected a misspelled word through ispell, one wanted to re-spellcheck the entire buffer. ispell-word offers no such functionality, even if the spellchecked word is used a thousand times. One could track down the definition of ispell-word, copy it into one's Emac, and write the additional functionality, but this is tedious, prone to broken-ness (the Emac version will get out of sync with the actual Ispell Elisp module, if it even works out of its home). What one wants is fairly simple: just to run another command after ispell-word runs. Using advice functions, it can be done as simply as this:</h3>
        <br></br>
        <h3>(defadvice ispell (after advice)
            (flyspell-buffer))
            (ad-activate 'ispell t)</h3>
        <h2>Implementations</h2>
        <h3>A form of advices were part of C with Classes in the late 1970s and early 1980s, namely functions called call and return defined in a class, which were called before (respectively, after) member functions of the class. However, these were dropped from C++.[3]

            Advices are part of the Common Lisp Object System (CLOS), as :before, :after, and :around methods, which are combined with the primary method under "standard method combination".[4]

            Common Lisp implementations provide advice functionality (in addition to the standard method combination for CLOS) as extensions. LispWorks[5] supports advising functions, macros and CLOS methods.

            EmacsLisp added advice-related code in version 19.28, 1994.</h3>
        <h2>Notes</h2>
        <h3>Gregor Kiczales comments the above as follows:

            Advice appeared separately from Flavors in Maclisp and the Lisp Machine. You could advise any function, just like in Interlisp at the time. The before/after ontology appeared separately in Flavors methods.
            Method combination and macros were only marginally related until much later, in New Flavors and CLOS, when a macro-like mechanism was provided to allow people to define their own rules for combining methods. Prior to that the rules governing combination of before/after methods and so-called whoppers methods (around) was fixed, and the compiler just generated the code for that. There were things called wrappers, which had macro-like behavior, but I forget when they came around. Traipsing through the various versions of MacLisp and Lispm manual to get this part of the history exactly right could be interesting. Or it could be that Howard Cannon or David Moon or someone could actually remember it all exactly.</h3>
        <h2>References</h2>
        <ul>
            <li class="ref"> See, for example, AIM-602 at https://web.archive.org/web/20060913001624/http://www.ai.mit.edu/research/publications/browse/0600browse.shtml</li>
            <li class="ref">See AIM-57 at https://web.archive.org/web/20060913001624/http://www.ai.mit.edu/research/publications/browse/0000browse.shtml</li>
            <li class="ref">The Design and Evolution of C++, p. 57</li>
            <li class="ref">"A Brief Guide to CLOS". Archived from the original on 2015-05-06. Retrieved 2015-04-27.</li>
            <li class="ref"> LispWorks 7 User Guide and Reference Manual, The Advice Facility</li>
        </ul>
        <hr>
        </hr>
        <h1 id="WIAP">What Is A Programmer?</h1>
        <h3>A computer programmer, sometimes called a software developer, a programmer or more recently a coder (especially in more informal contexts), is a person who creates computer software. The term computer programmer can refer to a specialist in one area of computers, or to a generalist who writes code for many kinds of software.

            A programmer's most oft-used computer language (e.g., Assembly, COBOL, C, C++, C#, JavaScript, Lisp, Python) may be prefixed to the term programmer. Some who work with web programming languages also prefix their titles with web.</h3>
        <h2>History</h2>
        <h3>British countess and mathematician Ada Lovelace is often considered to be the first computer programmer, as she was the first to publish part of a program (specifically an algorithm) intended for implementation on Charles Babbage's analytical engine, in October 1842. The algorithm was used to calculate Bernoulli numbers.[2] Because Babbage's machine was never completed as a functioning standard in Lovelace's time, she unfortunately never had the opportunity to see the algorithm in action.

            The first person to execute a program on a functioning, modern, electronic computer was the renowned computer scientist Konrad Zuse, in 1941.
            The ENIAC programming team, consisting of Kay McNulty, Betty Jennings, Betty Snyder, Marlyn Wescoff, Fran Bilas and Ruth Lichterman were the first regularly working programmers.[3][4] International Programmers' Day is celebrated annually on 7 January.[5] In 2009, the government of Russia decreed a professional annual holiday known as Programmers' Day to be celebrated on 13 September (12 September in leap years). It had already been an unofficial holiday before that in many countries.
            <h2>[Software]</h2>
            <h3>he word software was used as early as 1953, but did not regularly appear in print until the 1960s.[6] Before this time, computers were programmed either by customers or the few commercial computer manufacturers of the time, such as UNIVAC and IBM. The first company founded to specifically provide software products and services was the Computer Usage Company, in 1955.[7]

                The software industry expanded in the early 1960s, almost immediately after computers were first sold in mass-produced quantities. Universities, governments, and businesses created a demand for software. Many of these programs were written in-house by full-time staff programmers; some were distributed freely between users of a particular machine for no charge. And others were developed on a commercial basis. Other firms, such as Computer Sciences Corporation (founded in 1959) also started to grow. The computer/hardware manufacturers soon started bundling operating systems, system software and programming environments with their machines.[citation needed]

                The industry expanded greatly with the rise of the personal computer ("PC") in the mid-1970s, which brought computing to the average office worker. In thNature of the work following years the PC also helped create a constantly-growing market for games, applications and utilities software.[8]

                In the early years of the 21st century, another successful business model has arisen for hosted software, called software-as-a-service, or SaaS. From the point of view of producers of some proprietary software, SaaS reduces the concerns about unauthorized copying, since it can only be accessed through the Web, and by definition, no client software is loaded onto the end user's PC. SaaS is typically run out of the cloud.[9]</h3>
            <h2>[Nature of the work]</h2>
            <h3>Computer programmers write, test, debug, and maintain the detailed instructions, called computer programs, that computers must follow to perform their functions. Programmers also conceive, design, and test logical structures for solving problems by computer. Many technical innovations in programming — advanced computing technologies and sophisticated new languages and programming tools — have redefined the role of a programmer and elevated much of the programming work done today. Job titles and descriptions may vary, depending on the organization.

                Programmers work in many settings, including corporate information technology ("IT") departments, big software companies, small service firms and government entities of all sizes. Many professional programmers also work for consulting companies at client sites as contractors. Licensing is not typically required to work as a programmer, although professional certifications are commonly held by programmers. Programming is widely considered a profession (although some[who?] authorities disagree on the grounds that only careers with legal licensing requirements count as a profession).

                Programmers' work varies widely depending on the type of business for which they are writing programs. For example, the instructions involved in updating financial records are very different from those required to duplicate conditions on an aircraft for pilots training in a flight simulator. Simple programs can be written in a few hours, more complex ones may require more than a year of work, while others are never considered 'complete' but rather are continuously improved as long as they stay in use. In most cases, several programmers work together as a team under a senior programmer's supervision.
                Programmers write programs according to the specifications determined primarily by more senior programmers and by systems analysts. After the design process is complete, it is the job of the programmer to convert that design into a logical series of instructions that the computer can follow. The programmer codes these instructions in one of many programming languages. Different programming languages are used depending on the purpose of the program. COBOL, for example, is commonly used for business applications that typically run on mainframe and midrange computers, whereas Fortran is used in science and engineering. C++ and Python are widely used for both scientific and business applications. Java, C#, JS and PHP are popular programming languages for Web and business applications. Programmers generally know more than one programming language and, because many languages are similar, they often can learn new languages relatively easily. In practice, programmers often are referred to by the language they know, e.g. as Java programmers, or by the type of function they perform or the environment in which they work: for example, database programmers, mainframe programmers, or Web developers.

                When making changes to the source code that programs are made up of, programmers need to make other programmers aware of the task that the routine is to perform. They do this by inserting comments in the source code so that others can understand the program more easily and by documenting their code. To save work, programmers often use libraries of basic code that can be modified or customized for a specific application. This approach yields more reliable and consistent programs and increases programmers' productivity by eliminating some routine steps.</h3>
            <h2>[Testing and debugging]</h2>
            <h3>Programmers test a program by running it and looking for bugs (errors). As they are identified, the programmer usually makes the appropriate corrections, then rechecks the program until an acceptably low level and severity of bugs remain. This process is called testing and debugging. These are important parts of every programmer's job. Programmers may continue to fix these problems throughout the life of a program. Updating, repairing, modifying, and expanding existing programs is sometimes called maintenance programming. Programmers may contribute to user guides and online help, or they may work with technical writers to do such work.</h3>
            <h2>[Application versus system programming]</h2>
            <h3>Computer programmers often are grouped into two broad types: application programmers and systems programmers. Application programmers write programs to handle a specific job, such as a program to track inventory within an organization. They also may revise existing packaged software or customize generic applications which are frequently purchased from independent software vendors. Systems programmers, in contrast, write programs to maintain and control computer systems software, such as operating systems and database management systems. These workers make changes in the instructions that determine how the network, workstations, and CPU of the system handle the various jobs they have been given and how they communicate with peripheral equipment such as printers and disk drives.</h3>
            <h2>[Qualifications and skills]</h2>
            <h3>A software developer needs to have deep technical expertise with certain aspects of computing. Some positions will require a degree in a relevant field such as computer science, information technology, engineering, programming, or any other IT related post-graduate studies.[10] An ideal software developer is a self-motivated professional carrying a dynamic hands-on experience on key languages of programming such as C++, C#, PHP, Java, C, JavaScript, Visual Basic, Python, and Smalltalk.

                According to developer Eric Sink, the differences between system design, software development, and programming are more apparent. Already in the current market place, there can be found a segregation between programmers and developers, in that one who implements is not the same as the one who designs the class structure or hierarchy. Even more, so that developers become software architects or systems architects, those who design the multi-leveled architecture or component interactions of a large software system.[11]</h3>
            <h2>[Types of software]</h2>
            <h3>Programmers in software development companies may work directly with experts from various fields to create software – either programs designed for specific clients or packaged software for general use – ranging from video games to educational software to programs for desktop publishing and financial planning. Programming of packaged software constitutes one of the most rapidly growing segments of the computer services industry. Some companies or organizations – even small ones – have set up their own IT team to ensure the design and development of in-house software to answer to very specific needs from their internal end-users, especially when existing software are not suitable or too expensive. This is, for example, the case in research laboratories.[citation needed]

                In some organizations, particularly small ones, people commonly known as programmer analysts are responsible for both the systems analysis and the actual programming work. The transition from a mainframe environment to one that is based primarily on personal computers (PCs) has blurred the once rigid distinction between the programmer and the user. Increasingly, adept end-users are taking over many of the tasks previously performed by programmers. For example, the growing use of packaged software, such as spreadsheet and database management software packages, allows users to write simple programs to access data and perform calculations.[citation needed]

                In addition, the rise of the Internet has made web development a huge part of the programming field. Currently, more software applications are web applications that can be used by anyone with a web browser.[citation needed] Examples of such applications include the Google search service, the Outlook.com e-mail service, and the Flickr photo-sharing service.

                Programming editors, also known as source code editors, are text editors that are specifically designed for programmers or developers for writing the source code of an application or a program. Most of these editors include features useful for programmers, which may include color syntax highlighting, auto indentation, auto-complete, bracket matching, syntax check, and allows plug-ins. These features aid the users during coding, debugging and testing.[12]</h3>
            <h2>[Market changes in the UK]</h2>
            <h3>According to BBC News, 17% of computer science students could not find work in their field 6 months after graduation in 2009 which was the highest rate of the university subjects surveyed while 0% of medical students were unemployed in the same survey.[13] The UK category system does, however, class such degrees as information technology and game design as 'computer science', industries in which jobs can be extremely difficult to find, somewhat inflating the actual figure.[14]</h3>
            <h2>[Market changes in the US]</h2>
            <h3>Computer programming, offshore outsourcing, and Foreign Worker Visas became a controversial topic after the crash of the dot-com bubble left many programmers without work or with lower wages. Programming was even mentioned in the 2004 US Presidential debate on the topic of offshore outsourcing.[15]

                Large companies claim there is a skills shortage with regard to programming talent. However, US programmers and unions counter that large companies are exaggerating their case in order to obtain cheaper programmers from developing countries and avoid previously employer-paid training using industry-specific technologies not covered in most accredited degree programs.[16][17] Other reasons for employers claiming skill shortages is the result of their own cost-saving combining of several disparate skill sets previously held by several specialized programmers into fewer generalized multifaceted positions that are unlikely to have enough " qualified" candidates with the desired experience.[18]

                Enrollment in computer-related degrees in the US has dropped for years, especially for women[19], due to lack of general interests in science and mathematics and also out of an apparent fear that programming will be subject to the same pressures as manufacturing and agriculture careers.[20] This situation has resulted in confusion about whether the US economy is entering a "post-information age" and the nature of US comparative advantages. Most academic institutions have an Institutional research office that keeps past statistics of degrees conferred which shows several dips and rises in Computer Science degrees over the past 30 years. The overall trend shows a slightly overall decline in growth (especially when compared to other STEM degree growth) since certain peaks of 1986, 1992, 2002, and 2008 showing periods of flat growth or even declines.[21], In addition, the U.S. Bureau of Labor Statistics Occupational Outlook 2016-26 a decline of 7 percent and a decline of 9 percent from 2019 to 2029 [22] is expected for Computer Programmers because Computer programming can be done from anywhere in the world, so companies sometimes hire programmers in countries where wages are lower.[23]</h3>
            <h2>[Country comparison]</h2>
            <h3>Russia and China are the countries that are ranked very high when it comes to talent in computer programming.[24][25]</h3>
            <hr>
            </hr>
            <h1 id="PL">Programming Language</h1>
            <h3>A programming language is a formal language comprising a set of instructions that produce various kinds of output. Programming languages are used in computer programming to implement algorithms.

                Most programming languages consist of instructions for computers. There are programmable machines that use a set of specific instructions, rather than general programming languages. Early ones preceded the invention of the digital computer, the first probably being the automatic flute player described in the 9th century by the brothers Musa in Baghdad, during the Islamic Golden Age.[1] Since the early 1800s, programs have been used to direct the behavior of machines such as Jacquard looms, music boxes and player pianos.[2] The programs for these machines (such as a player piano's scrolls) did not produce different behavior in response to different inputs or conditions.

                Thousands of different programming languages have been created, and more are being created every year. Many programming languages are written in an imperative form (i.e., as a sequence of operations to perform) while other languages use the declarative form (i.e. the desired result is specified, not how to achieve it).

                The description of a programming language is usually split into the two components of syntax (form) and semantics (meaning). Some languages are defined by a specification document (for example, the C programming language is specified by an ISO Standard) while other languages (such as Perl) have a dominant implementation that is treated as a reference. Some languages have both, with the basic language defined by a standard and extensions taken from the dominant implementation being common.</h3>
            <h2>[Definitions]</h2>
            <h3>A programming language is a notation for writing programs, which are specifications of a computation or algorithm.[3] Some authors restrict the term "programming language" to those languages that can express all possible algorithms.[3][4] Traits often considered important for what constitutes a programming language include:
                A computer programming language is a language used to write computer programs, which involves a computer performing some kind of computation[5] or algorithm and possibly control external devices such as printers, disk drives, robots,[6] and so on. For example, PostScript programs are frequently created by another program to control a computer printer or display. More generally, a programming language may describe computation on some, possibly abstract, machine. It is generally accepted that a complete specification for a programming language includes a description, possibly idealized, of a machine or processor for that language.[7] In most practical contexts, a programming language involves a computer; consequently, programming languages are usually defined and studied this way.[8] Programming languages differ from natural languages in that natural languages are only used for interaction between people, while programming languages also allow humans to communicate instructions to machines.
                Programming languages usually contain abstractions for defining and manipulating data structures or controlling the flow of execution. The practical necessity that a programming language support adequate abstractions is expressed by the abstraction principle.[9] This principle is sometimes formulated as a recommendation to the programmer to make proper use of such abstractions.[10]
                The theory of computation classifies languages by the computations they are capable of expressing. All Turing complete languages can implement the same set of algorithms. ANSI/ISO SQL-92 and Charity are examples of languages that are not Turing complete, yet are often called programming languages.[11][12]
                Markup languages like XML, HTML, or troff, which define structured data, are not usually considered programming languages.[13][14][15] Programming languages may, however, share the syntax with markup languages if a computational semantics is defined. XSLT, for example, is a Turing complete language entirely using XML syntax.[16][17][18] Moreover, LaTeX, which is mostly used for structuring documents, also contains a Turing complete subset.[19][20]

                The term computer language is sometimes used interchangeably with programming language.[21] However, the usage of both terms varies among authors, including the exact scope of each. One usage describes programming languages as a subset of computer languages.[22] Similarly, languages used in computing that have a different goal than expressing computer programs are generically designated computer languages. For instance, markup languages are sometimes referred to as computer languages to emphasize that they are not meant to be used for programming.[23]

                Another usage regards programming languages as theoretical constructs for programming abstract machines, and computer languages as the subset thereof that runs on physical computers, which have finite hardware resources.[24] John C. Reynolds emphasizes that formal specification languages are just as much programming languages as are the languages intended for execution. He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats.[25]</h3>
            <h2>[History]</h2>
            <h3>Early developments
                Very early computers, such as Colossus, were programmed without the help of a stored program, by modifying their circuitry or setting banks of physical controls.

                Slightly later, programs could be written in machine language, where the programmer writes each instruction in a numeric form the hardware can execute directly. For example, the instruction to add the value in two memory location might consist of 3 numbers: an "opcode" that selects the "add" operation, and two memory locations. The programs, in decimal or binary form, were read in from punched cards, paper tape, magnetic tape or toggled in on switches on the front panel of the computer. Machine languages were later termed first-generation programming languages (1GL).

                The next step was development of so-called second-generation programming languages (2GL) or assembly languages, which were still closely tied to the instruction set architecture of the specific computer. These served to make the program much more human-readable and relieved the programmer of tedious and error-prone address calculations.

                The first high-level programming languages, or third-generation programming languages (3GL), were written in the 1950s. An early high-level programming language to be designed for a computer was Plankalkül, developed for the German Z3 by Konrad Zuse between 1943 and 1945. However, it was not implemented until 1998 and 2000.[26]

                John Mauchly's Short Code, proposed in 1949, was one of the first high-level languages ever developed for an electronic computer.[27] Unlike machine code, Short Code statements represented mathematical expressions in understandable form. However, the program had to be translated into machine code every time it ran, making the process much slower than running the equivalent machine code.

                At the University of Manchester, Alick Glennie developed Autocode in the early 1950s. As a programming language, it used a compiler to automatically convert the language into machine code. The first code and compiler was developed in 1952 for the Mark 1 computer at the University of Manchester and is considered to be the first compiled high-level programming language.[28][29]

                The second autocode was developed for the Mark 1 by R. A. Brooker in 1954 and was called the "Mark 1 Autocode". Brooker also developed an autocode for the Ferranti Mercury in the 1950s in conjunction with the University of Manchester. The version for the EDSAC 2 was devised by D. F. Hartley of University of Cambridge Mathematical Laboratory in 1961. Known as EDSAC 2 Autocode, it was a straight development from Mercury Autocode adapted for local circumstances and was noted for its object code optimisation and source-language diagnostics which were advanced for the time. A contemporary but separate thread of development, Atlas Autocode was developed for the University of Manchester Atlas 1 machine.

                In 1954, FORTRAN was invented at IBM by John Backus. It was the first widely used high-level general purpose programming language to have a functional implementation, as opposed to just a design on paper.[30][31] It is still a popular language for high-performance computing[32] and is used for programs that benchmark and rank the world's fastest supercomputers.[33]

                Another early programming language was devised by Grace Hopper in the US, called FLOW-MATIC. It was developed for the UNIVAC I at Remington Rand during the period from 1955 until 1959. Hopper found that business data processing customers were uncomfortable with mathematical notation, and in early 1955, she and her team wrote a specification for an English programming language and implemented a prototype.[34] The FLOW-MATIC compiler becAPL introduced array programming and influenced functional programming.[37]</li>
                <h2>[Refinement]</h2>
                <h3>The increased use of high-level languages introduced a requirement for low-level programming languages or system programming languages. These languages, to varying degrees, provide facilities between assembly languages and high-level languages. They can be used to perform tasks which require direct access to hardware faciecking.

                    The period from the 1960s to the late 1970s brought the development of the major language paradigms now in use:</h3>
                <ul>
                    <li class="rfi">APL introduced array programming and influenced functional programming.[37]</li>
                    <li class="rfi">ALGOL refined both structured procedural programming and the discipline of language specification; the "Revised Report on the Algorithmic Language ALGOL 60" became a model for how later language specifications were written.</li>
                    <li class="rfi">Lisp, implemented in 1958, was the first dynamically typed functional programming language.</li>
                    <li class="rfi">In the 1960s, Simula was the first language designed to support object-oriented programming; in the mid-1970s, Smalltalk followed with the first "purely" object-oriented language</li>
                </ul>
                <h2>[Consolidation and growth]</h2>
                <h3>The 1980s were years of relative consolidation. C++ combined object-oriented and systems programming. The United States government standardized Ada, a systems programming language derived from Pascal and intended for use by defense contractors. In Japan and elsewhere, vast sums were spent investigating so-called "fifth-generation" languages that incorporated logic programming constructs.[41] The functional languages community moved to standardize ML and Lisp. Rather than inventing new paradigms, all of these movements elaborated upon the ideas invented in the previous decades.

                    One important trend in language design for programming large-scale systems during the 1980s was an increased focus on the use of modules or large-scale organizational units of code. Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs.[42]

                    The rapid growth of the Internet in the mid-1990s created opportunities for new languages. Perl, originally a Unix scripting tool first released in 1987, became common in dynamic websites. Java came to be used for server-side programming, and bytecode virtual machines became popular again in commercial settings with their promise of "Write once, run anywhere" (UCSD Pascal had been popular for a time in the early 1980s). These developments were not fundamentally novel; rather, they were refinements of many existing languages and paradigms (although their syntax was often based on the C family of programming languages).

                    Programming language evolution continues, in both industry and research. Current directions include security and reliability verification, new kinds of modularity (mixins, delegates, aspects), and database integration such as Microsoft's LINQ.

                    Fourth-generation programming languages (4GL) are computer programming languages which aim to provide a higher level of abstraction of the internal computer hardware details than 3GLs. Fifth-generation programming languages (5GL) are programming languages based on solving problems using constraints given to the program, rather than using an algorithm written by a programmer.</h3>
                <h2>Elements</h2>
                <h3>All programming languages have some primitive building blocks for the description of data and the processes or transformations applied to them (like the addition of two numbers or the selection of an item from a collection). These primitives are defined by syntactic and semantic rules which describe their structure and meaning respectively.</h3>
                <h2>[Syntax]</h2>
                <h3>A programming language's surface form is known as its syntax. Most programming languages are purely textual; they use sequences of text including words, numbers, and punctuation, much like written natural languages. On the other hand, there are some programming languages which are more graphical in nature, using visual relationships between symbols to specify a program.

                    The syntax of a language describes the possible combinations of symbols that form a syntactically correct program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Since most languages are textual, this article discusses textual syntax.

                    Programming language syntax is usually defined using a combination of regular expressions (for lexical structure) and Backus–Naur form (for grammatical structure). Below is a simple grammar, based on Lisp:

                    expression ::= atom | list
                    atom ::= number | symbol
                    number ::= [+-]?['0'-'9']+
                    symbol ::= ['A'-'Z''a'-'z'].*
                    list ::= '(' expression* ')'
                    This grammar specifies the following:</h3>
                <ul>
                    <li class="SY">an expression is either an atom or a list;</li>
                    <li class="SY">an atom is either a number or a symbol;</li>
                    <li class="SY">a number is an unbroken sequence of one or more decimal digits, optionally preceded by a plus or minus sign;</li>
                    <li class="SY">a symbol is a letter followed by zero or more of any characters (excluding whitespace); and
                        a list is a matched pair of parentheses, with zero or more expressions inside it.</li>
                </ul>
                <h3>The following are examples of well-formed token sequences in this grammar: 12345, () and (a b c232 (1)).

                    Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.

                    Using natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:

                    "Colorless green ideas sleep furiously." is grammatically well-formed but has no generally accepted meaning.
                    "John is a married bachelor." is grammatically well-formed but expresses a meaning that cannot be true.
                    The following C language fragment is syntactically correct, but performs operations that are not semantically defined (the operation *p >> 4 has no meaning for a value having a complex type and p->im is not defined because the value of p is the null pointer):

                    complex *p = NULL;
                    complex abs_p = sqrt(*p >> 4 + p->im);
                    If the type declaration on the first line were omitted, the program would trigger an error on undefined variable "p" during compilation. However, the program would still be syntactically correct since type declarations provide only semantic information.

                    The grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The syntax of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars.[43] Some languages, including Perl and Lisp, contain constructs that allow execution during the parsing phase. Languages that have constructs that allow the programmer to alter the behavior of the parser make syntax analysis an undecidable problem, and generally blur the distinction between parsing and execution.[44] In contrast to Lisp's macro system and Perl's BEGIN blocks, which may contain general computations, C macros are merely string replacements and do not require code execution.[45]</h3>
                <h2>[Static semantics]</h2>
                <h3>The static semantics defines restrictions on the structure of valid texts that are hard or impossible to express in standard syntactic formalisms.[3] For compiled languages, static semantics essentially include those semantic rules that can be checked at compile time. Examples include checking that every identifier is declared before it is used (in languages that require such declarations) or that the labels on the arms of a case statement are distinct.[46] Many important restrictions of this type, like checking that identifiers are used in the appropriate context (e.g. not adding an integer to a function name), or that subroutine calls have the appropriate number and type of arguments, can be enforced by defining them as rules in a logic called a type system. Other forms of static analyses like data flow analysis may also be part of static semantics. Newer programming languages like Java and C# have definite assignment analysis, a form of data flow analysis, as part of their static semantics.</h3>
                <h2>[Dynamic semantics]</h2>
                <h3>Once data has been specified, the machine must be instructed to perform operations on the data. For example, the semantics may define the strategy by which expressions are evaluated to values, or the manner in which control structures conditionally execute statements. The dynamic semantics (also known as execution semantics) of a language defines how and when the various constructs of a language should produce a program behavior. There are many ways of defining execution semantics. Natural language is often used to specify the execution semantics of languages commonly used in practice. A significant amount of academic research went into formal semantics of programming languages, which allow execution semantics to be specified in a formal manner. Results from this field of research have seen limited application to programming language design and implementation outside academia.</h3>
                <h2>[Type system]</h2>
                <h3>A type system defines how a programming language classifies values and expressions into types, how it can manipulate those types and how they interact. The goal of a type system is to verify and usually enforce a certain level of correctness in programs written in that language by detecting certain incorrect operations. Any decidable type system involves a trade-off: while it rejects many incorrect programs, it can also prohibit some correct, albeit unusual programs. In order to bypass this downside, a number of languages have type loopholes, usually unchecked casts that may be used by the programmer to explicitly allow a normally disallowed operation between different types. In most typed languages, the type system is used only to type check programs, but a number of languages, usually functional ones, infer types, relieving the programmer from the need to write type annotations. The formal design and study of type systems is known as type theory.

                    Typed versus untyped languages
                    A language is typed if the specification of every operation defines types of data to which the operation is applicable.[47] For example, the data represented by "this text between the quotes" is a string, and in many programming languages dividing a number by a string has no meaning and will not be executed. The invalid operation may be detected when the program is compiled ("static" type checking) and will be rejected by the compiler with a compilation error message, or it may be detected while the program is running ("dynamic" type checking), resulting in a run-time exception. Many languages allow a function called an exception handler to handle this exception and, for example, always return "-1" as the result.

                    A special case of typed languages are the single-typed languages. These are often scripting or markup languages, such as REXX or SGML, and have only one data type[dubious – discuss]–—most commonly character strings which are used for both symbolic and numeric data.

                    In contrast, an untyped language, such as most assembly languages, allows any operation to be performed on any data, generally sequences of bits of various lengths.[47] High-level untyped languages include BCPL, Tcl, and some varieties of Forth.

                    In practice, while few languages are considered typed from the type theory (verifying or rejecting all operations), most modern languages offer a degree of typing.[47] Many production languages provide means to bypass or subvert the type system, trading type-safety for finer control over the program's execution (see casting).

                    Static versus dynamic typing
                    In static typing, all expressions have their types determined prior to when the program is executed, typically at compile-time. For example, 1 and (2+2) are integer expressions; they cannot be passed to a function that expects a string, or stored in a variable that is defined to hold dates.[47]

                    Statically typed languages can be either manifestly typed or type-inferred. In the first case, the programmer must explicitly write types at certain textual positions (for example, at variable declarations). In the second case, the compiler infers the types of expressions and declarations based on context. Most mainstream statically typed languages, such as C++, C# and Java, are manifestly typed. Complete type inference has traditionally been associated with less mainstream languages, such as Haskell and ML. However, many manifestly typed languages support partial type inference; for example, C++, Java and C# all infer types in certain limited cases.[48] Additionally, some programming languages allow for some types to be automatically converted to other types; for example, an int can be used where the program expects a float.

                    Dynamic typing, also called latent typing, determines the type-safety of operations at run time; in other words, types are associated with run-time values rather than textual expressions.[47] As with type-inferred languages, dynamically typed languages do not require the programmer to write explicit type annotations on expressions. Among other things, this may permit a single variable to refer to values of different types at different points in the program execution. However, type errors cannot be automatically detected until a piece of code is actually executed, potentially making debugging more difficult. Lisp, Smalltalk, Perl, Python, JavaScript, and Ruby are all examples of dynamically typed languages.

                    Weak and strong typing
                    Weak typing allows a value of one type to be treated as another, for example treating a string as a number.[47] This can occasionally be useful, but it can also allow some kinds of program faults to go undetected at compile time and even at run time.

                    Strong typing prevents these program faults. An attempt to perform an operation on the wrong type of value raises an error.[47] Strongly typed languages are often termed type-safe or safe.

                    An alternative definition for "weakly typed" refers to languages, such as Perl and JavaScript, which permit a large number of implicit type conversions. In JavaScript, for example, the expression 2 * x implicitly converts x to a number, and this conversion succeeds even if x is null, undefined, an Array, or a string of letters. Such implicit conversions are often useful, but they can mask programming errors. Strong and static are now generally considered orthogonal concepts, but usage in the literature differs. Some use the term strongly typed to mean strongly, statically typed, or, even more confusingly, to mean simply statically typed. Thus C has been called both strongly typed and weakly, statically typed.[49][50]

                    It may seem odd to some professional programmers that C could be "weakly, statically typed". However, notice that the use of the generic pointer, the void* pointer, does allow for casting of pointers to other pointers without needing to do an explicit cast. This is extremely similar to somehow casting an array of bytes to any kind of datatype in C without using an explicit cast, such as (int) or (char).

                    Standard library and run-time system
                    Main article: Standard library
                    Most programming languages have an associated core library (sometimes known as the 'standard library', especially if it is included as part of the published language standard), which is conventionally made available by all implementations of the language. Core libraries typically include definitions for commonly used algorithms, data structures, and mechanisms for input and output.

                    The line between a language and its core library differs from language to language. In some cases, the language designers may treat the library as a separate entity from the language. However, a language's core library is often treated as part of the language by its users, and some language specifications even require that this library be made available in all implementations. Indeed, some languages are designed so that the meanings of certain syntactic constructs cannot even be described without referring to the core library. For example, in Java, a string literal is defined as an instance of the java.lang.String class; similarly, in Smalltalk, an anonymous function expression (a "block") constructs an instance of the library's BlockContext class. Conversely, Scheme contains multiple coherent subsets that suffice to construct the rest of the language as library macros, and so the language designers do not even bother to say which portions of the language must be implemented as language constructs, and which must be implemented as parts of a library.</h3>
                <h2>Design and implementation</h2>
                <h3>Programming languages share properties with natural languages related to their purpose as vehicles for communication, having a syntactic form separate from its semantics, and showing language families of related languages branching one from another.[51][52] But as artificial constructs, they also differ in fundamental ways from languages that have evolved through usage. A significant difference is that a programming language can be fully described and studied in its entirety, since it has a precise and finite definition.[53] By contrast, natural languages have changing meanings given by their users in different communities. While constructed languages are also artificial languages designed from the ground up with a specific purpose, they lack the precise and complete semantic definition that a programming language has.

                    Many programming languages have been designed from scratch, altered to meet new needs, and combined with other languages. Many have eventually fallen into disuse. Although there have been attempts to design one "universal" programming language that serves all purposes, all of them have failed to be generally accepted as filling this role.[54] The need for diverse programming languages arises from the diversity of contexts in which languages are used:

                    Programs range from tiny scripts written by individual hobbyists to huge systems written by hundreds of programmers.
                    Programmers range in expertise from novices who need simplicity above all else, to experts who may be comfortable with considerable complexity.
                    Programs must balance speed, size, and simplicity on systems ranging from microcontrollers to supercomputers.
                    Programs may be written once and not change for generations, or they may undergo continual modification.
                    Programmers may simply differ in their tastes: they may be accustomed to discussing problems and expressing them in a particular language.
                    One common trend in the development of programming languages has been to add more ability to solve problems using a higher level of abstraction. The earliest programming languages were tied very closely to the underlying hardware of the computer. As new programming languages have developed, features have been added that let programmers express ideas that are more remote from simple translation into underlying hardware instructions. Because programmers are less tied to the complexity of the computer, their programs can do more computing with less effort from the programmer. This lets them write more functionality per time unit.[55]

                    Natural language programming has been proposed as a way to eliminate the need for a specialized language for programming. However, this goal remains distant and its benefits are open to debate. Edsger W. Dijkstra took the position that the use of a formal language is essential to prevent the introduction of meaningless constructs, and dismissed natural language programming as "foolish".[56] Alan Perlis was similarly dismissive of the idea.[57] Hybrid approaches have been taken in Structured English and SQL.

                    A language's designers and users must construct a number of artifacts that govern and enable the practice of programming. The most important of these artifacts are the language specification and implementation.</h3>
                <h2>[Specification]<h2>
                        <h3>The specification of a programming language is an artifact that the language users and the implementors can use to agree upon whether a piece of source code is a valid program in that language, and if so what its behavior shall be.

                            A programming language specification can take several forms, including the following:

                            An explicit definition of the syntax, static semantics, and execution semantics of the language. While syntax is commonly specified using a formal grammar, semantic definitions may be written in natural language (e.g., as in the C language), or a formal semantics (e.g., as in Standard ML[58] and Scheme[59] specifications).
                            A description of the behavior of a translator for the language (e.g., the C++ and Fortran specifications). The syntax and semantics of the language have to be inferred from this description, which may be written in natural or a formal language.
                            A reference or model implementation, sometimes written in the language being specified (e.g., Prolog or ANSI REXX[60]). The syntax and semantics of the language are explicit in the behavior of the reference implementation.</h3>
                        <h2>[Implemention]</h2>
                        <h3>An implementation of a programming language provides a way to write programs in that language and execute them on one or more configurations of hardware and software. There are, broadly, two approaches to programming language implementation: compilation and interpretation. It is generally possible to implement a language using either technique.

                            The output of a compiler may be executed by hardware or a program called an interpreter. In some implementations that make use of the interpreter approach there is no distinct boundary between compiling and interpreting. For instance, some implementations of BASIC compile and then execute the source a line at a time.

                            Programs that are executed directly on the hardware usually run much faster than those that are interpreted in software.[61][better source needed]

                            One technique for improving the performance of interpreted programs is just-in-time compilation. Here the virtual machine, just before execution, translates the blocks of bytecode which are going to be used to machine code, for direct execution on the hardware.</h3>
                        <h2>[Proprietary languages]</h2>
                        <h3>Although most of the most commonly used programming languages have fully open specifications and implementations, many programming languages exist only as proprietary programming languages with the implementation available only from a single vendor, which may claim that such a proprietary language is their intellectual property. Proprietary programming languages are commonly domain specific languages or internal scripting languages for a single product; some proprietary languages are used only internally within a vendor, while others are available to external users.

                            Some programming languages exist on the border between proprietary and open; for example, Oracle Corporation asserts proprietary rights to some aspects of the Java programming language,[62] and Microsoft's C# programming language, which has open implementations of most parts of the system, also has Common Language Runtime (CLR) as a closed environment.[63]

                            Many proprietary languages are widely used, in spite of their proprietary nature; examples include MATLAB, VBScript, and Wolfram Language. Some languages may make the transition from closed to open; for example, Erlang was originally an Ericsson's internal programming language.[64]</h3>
                        <h2>Use</h2>
                        <h3>Thousands of different programming languages have been created, mainly in the computing field.[65] Individual software projects commonly use five programming languages or more.[66]

                            Programming languages differ from most other forms of human expression in that they require a greater degree of precision and completeness. When using a natural language to communicate with other people, human authors and speakers can be ambiguous and make small errors, and still expect their intent to be understood. However, figuratively speaking, computers "do exactly what they are told to do", and cannot "understand" what code the programmer intended to write. The combination of the language definition, a program, and the program's inputs must fully specify the external behavior that occurs when the program is executed, within the domain of control of that program. On the other hand, ideas about an algorithm can be communicated to humans without the precision required for execution by using pseudocode, which interleaves natural language with code written in a programming language.

                            A programming language provides a structured mechanism for defining pieces of data, and the operations or transformations that may be carried out automatically on that data. A programmer uses the abstractions present in the language to represent the concepts involved in a computation. These concepts are represented as a collection of the simplest elements available (called primitives).[67] Programming is the process by which programmers combine these primitives to compose new programs, or adapt existing ones to new uses or a changing environment.

                            Programs for a computer might be executed in a batch process without human interaction, or a user might type commands in an interactive session of an interpreter. In this case the "commands" are simply programs, whose execution is chained together. When a language can run its commands through an interpreter (such as a Unix shell or other command-line interface), without compiling, it is called a scripting language.[68]

                            Measuring language usage
                            Main article: Measuring programming language popularity
                            Determining which is the most widely used programming language is difficult since the definition of usage varies by context. One language may occupy the greater number of programmer hours, a different one has more lines of code, and a third may consume the most CPU time. Some languages are very popular for particular kinds of applications. For example, COBOL is still strong in the corporate data center, often on large mainframes;[69][70] Fortran in scientific and engineering applications; Ada in aerospace, transportation, military, real-time and embedded applications; and C in embedded applications and operating systems. Other languages are regularly used to write many different kinds of applications.

                            Various methods of measuring language popularity, each subject to a different bias over what is measured, have been proposed:

                            counting the number of job advertisements that mention the language[71]
                            the number of books sold that teach or describe the language[72]
                            estimates of the number of existing lines of code written in the language – which may underestimate languages not often found in public searches[73]
                            counts of language references (i.e., to the name of the language) found using a web search engine.
                            Combining and averaging information from various internet sites, stackify.com reported the ten most popular programming languages as (in descending order by overall popularity): Java, C, C++, Python, C#, JavaScript, VB .NET, R, PHP, and MATLAB.[74]</h3>
                        <h2>Dialects, flavors and implementations</h2>
                        <h3>A dialect of a programming language or a data exchange language is a (relatively small) variation or extension of the language that does not change its intrinsic nature. With languages such as Scheme and Forth, standards may be considered insufficient, inadequate or illegitimate by implementors, so often they will deviate from the standard, making a new dialect. In other cases, a dialect is created for use in a domain-specific language, often a subset. In the Lisp world, most languages that use basic S-expression syntax and Lisp-like semantics are considered Lisp dialects, although they vary wildly, as do, say, Racket and Clojure. As it is common for one language to have several dialects, it can become quite difficult for an inexperienced programmer to find the right documentation. The BASIC programming language has many dialects.

                            The explosion of Forth dialects led to the saying "If you've seen one Forth... you've seen one Forth."</h3>
                        <h2>Taxonomies</h2>
                        <h3>There is no overarching classification scheme for programming languages. A given programming language does not usually have a single ancestor language. Languages commonly arise by combining the elements of several predecessor languages with new ideas in circulation at the time. Ideas that originate in one language will diffuse throughout a family of related languages, and then leap suddenly across familial gaps to appear in an entirely different family.

                            The task is further complicated by the fact that languages can be classified along multiple axes. For example, Java is both an object-oriented language (because it encourages object-oriented organization) and a concurrent language (because it contains built-in constructs for running multiple threads in parallel). Python is an object-oriented scripting language.

                            In broad strokes, programming languages divide into programming paradigms and a classification by intended domain of use, with general-purpose programming languages distinguished from domain-specific programming languages. Traditionally, programming languages have been regarded as describing computation in terms of imperative sentences, i.e. issuing commands. These are generally called imperative programming languages. A great deal of research in programming languages has been aimed at blurring the distinction between a program as a set of instructions and a program as an assertion about the desired answer, which is the main feature of declarative programming.[75] More refined paradigms include procedural programming, object-oriented programming, functional programming, and logic programming; some languages are hybrids of paradigms or multi-paradigmatic. An assembly language is not so much a paradigm as a direct model of an underlying machine architecture. By purpose, programming languages might be considered general purpose, system programming languages, scripting languages, domain-specific languages, or concurrent/distributed languages (or a combination of these).[76] Some general purpose languages were designed largely with educational goals.[77]

                            A programming language may also be classified by factors unrelated to programming paradigm. For instance, most programming languages use English language keywords, while a minority do not. Other languages may be classified as being deliberately esoteric or not.</h3>
                        <hr>
                        </hr>
                        <h1 id="V">Videos Of Coding</h1>
                        <iframe width="800" height="500" src="https://www.youtube.com/embed/HIj8wU_rGIU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        <br></br>
                        <br></br>
                        <iframe width="800" height="500" src="https://www.youtube.com/embed/U8_8fTODn5g" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        <hr>
                        <h1 id="C">View Review of Coding</h1>
                        <a class="Wiki" href="https://en.wikipedia.org/wiki/Code_review" target="_blank">
                            View Review Of Coding By Wikipedia.</a>
                        <hr>
                        <h1 id="I">Inspiration</h1>
                        <h2>Click on the pictures to view my Inspirations</h2>
                        <div class="container1">
                            <h2>1.Ada Lovelace</h2>
                            <span>
                                <a href="https://en.wikipedia.org/wiki/Ada_Lovelace" target="blank">
                                    <img src="https://i1.wp.com/metro.co.uk/wp-content/uploads/2013/10/ay95895977ada-lovelace-engl1.jpg?quality=90&strip=all&zoom=1&resize=644%2C701&ssl=1" class="A"></a>

                        </div>

                        <div class="container2">
                            <h2>2.Bill Gates</h2>
                            <span>
                                <a href="https://en.wikipedia.org/wiki/Bill_Gates" target="blank">
                                    <img src="https://pbs.twimg.com/profile_images/988775660163252226/XpgonN0X_400x400.jpg" class="A">
                                </a>
                        </div>
                        <hr>
                        <h1>Contacts</h1>
                        <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3769.588348679713!2d72.88846041455147!3d19.12570675537909!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3be7c97f346053b7%3A0xacf72f56793d190a!2sWhitehat%20Education%20Technology%20Pvt.%20Ltd.!5e0!3m2!1sen!2sin!4v1604637692240!5m2!1sen!2sin" width="900" height="900" frameborder="0" style="border:0;" allowfullscreen="" aria-hidden="false" tabindex="0"></iframe>
</body>

</html>
